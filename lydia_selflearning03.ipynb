{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lydia-selflearning03.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMTZh1EM28zTl3BTHdHWVBa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lydiamao/pytorch-learning_colab/blob/main/lydia_selflearning03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvFl9CtKI5Sb"
      },
      "outputs": [],
      "source": [
        " #1 加载必要的库\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "import torch.optim as optim\n",
        "from torchvision import datasets,transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2 定义超参数\n",
        "BATCH_SIZE=32 #每批处理的数据\n",
        "DEVICE=torch.device(\"cuda\") #用GPU\n",
        "EPOCHS=20 #训练数据集的轮次，把一个数据集循环运行几轮"
      ],
      "metadata": {
        "id": "B27sIuKfmbg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3 构建pipeline，对图像做处理\n",
        "pipeline=transforms.Compose([\n",
        "    transforms.ToTensor(), #将图片转化成tensor\n",
        "    transforms.Normalize((0.1307,),(0.3081,)) # 正则化，模型出现过拟合现象时，降低模型复杂度\n",
        "])"
      ],
      "metadata": {
        "id": "wtASAhl7mfd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4 下载，加载数据\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "#下载数据集\n",
        "train_set=datasets.MNIST(\"data\",train=True,download=True, transform=pipeline)\n",
        "\n",
        "test_set=datasets.MNIST(\"data\",train=False, download=True, transform=pipeline)\n",
        "\n",
        "#加载数据\n",
        "train_loader=DataLoader(train_set,batch_size=BATCH_SIZE,shuffle=True)\n",
        "\n",
        "test_loader=DataLoader(test_set,batch_size=BATCH_SIZE,shuffle=True)"
      ],
      "metadata": {
        "id": "KuFhq3IFmj6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#插入代码，显示MNIST中的图片\n",
        "with open(\"./data/MNIST/raw/train-images-idx3-ubyte\",\"rb\") as f:\n",
        "  file=f.read()"
      ],
      "metadata": {
        "id": "UEmtth5fwkGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "/content/data/MNIST/raw/train-images-idx3-ubyte"
      ],
      "metadata": {
        "id": "jLfjGKIuwFTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjlCJOtAvjag",
        "outputId": "b61cc687-a0b1-426a-c9d0-ff11ede472ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image1=[int(str(item).encode('ascii'),16)for item in file[16:16+784]]\n",
        "print(image1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXNsq0pJmmF0",
        "outputId": "d06cb9ea-3e36-446a-a980-f71dc1b38876"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 24, 24, 24, 294, 310, 373, 38, 358, 597, 583, 295, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 48, 54, 148, 340, 368, 595, 595, 595, 595, 595, 549, 370, 595, 578, 405, 100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 73, 568, 595, 595, 595, 595, 595, 595, 595, 595, 593, 147, 130, 130, 86, 57, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 24, 537, 595, 595, 595, 595, 595, 408, 386, 583, 577, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 128, 342, 263, 595, 595, 517, 17, 0, 67, 340, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20, 1, 340, 595, 144, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 313, 595, 400, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 17, 400, 595, 112, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 53, 577, 549, 352, 264, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 129, 576, 595, 595, 281, 37, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 69, 390, 595, 595, 336, 39, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 22, 147, 594, 595, 391, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 585, 595, 585, 100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 70, 304, 387, 595, 595, 519, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 57, 328, 553, 595, 595, 595, 592, 386, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 36, 276, 545, 595, 595, 595, 595, 513, 120, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 35, 102, 531, 595, 595, 595, 595, 408, 129, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 24, 369, 537, 595, 595, 595, 595, 405, 128, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 85, 370, 550, 595, 595, 595, 595, 580, 307, 17, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 310, 595, 595, 595, 530, 309, 306, 22, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "image1_np=np.array(image1,dtype=np.uint8).reshape(28,28,1) #uint8无符号整型\n",
        "print(image1_np.shape) #图片的高宽以及通道"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66iCMYZJzDKO",
        "outputId": "7a35d460-8ba1-48ed-87fe-bcfc4d684613"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#图片保存\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cv2.imwrite(\"digit.jpg\",image1_np)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdivYn6I2R54",
        "outputId": "adb9881e-4c8e-4cb9-b3ed-8653557919a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#5 构建网络模型\n",
        "class Digit(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    #定义卷积层\n",
        "    self.conv1=nn.Conv2d(1,10,5) #1:灰度图片的通道，10:输出通道，5:kernel\n",
        "    self.conv2=nn.Conv2d(10,20,3) #10:输入通道，20:输出通道，3:kernel\n",
        "    #定义全连接层\n",
        "    self.fc1=nn.Linear(20*10*10,500) #20*10*10:输入通道，500:输出通道\n",
        "    self.fc2=nn.Linear(500,10) #500:输入通道，10:输出10类\n",
        "  \n",
        "\n",
        "    #定义前向传播\n",
        "  def forward(self,x):\n",
        "    input_size=x.size(0) #一批数据输入进模型的格式(张量形式)是：batch_size x 1 (图片的通道，灰度) x 28 x28 \n",
        "                          #拿到batch_size\n",
        "    x=self.conv1(x) #输入：batch_size*1*28*28, 输出：batch*10*24*24 (28-5+1=24)\n",
        "    x=F.relu(x) #激活层，保持shape不变，输出：batch*10*24*24\n",
        "    x=F.max_pool2d(x,2,2) #池化层，输入batch*10*24*24，输出：batch*10*12*12\n",
        "    \n",
        "    #调用第二个卷积层\n",
        "    x=self.conv2(x) #输入：batch*10*12*12，输出：batch*20*10*10 (12-3+1=10)\n",
        "    x=F.relu(x)\n",
        "\n",
        "    x=x.view(input_size,-1) #拉平flatten，-1 自动计算维度，20*10*10=2000\n",
        "\n",
        "    #送入全连接层\n",
        "    x=self.fc1(x) #输入：batch*2000，输出：batch*500\n",
        "    x=F.relu(x) #输出：batch*500\n",
        "\n",
        "    #第二层全连接层\n",
        "    x=self.fc2(x) #输入：batch*500，输出：batch*10\n",
        "\n",
        "    #分类\n",
        "    output=F.log_softmax(x,dim=1) #计算分类后，每个数字的概率值\n",
        "    return output\n",
        "\n"
      ],
      "metadata": {
        "id": "rcHE8bgRy-CB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6 定义优化器\n",
        "model = Digit().to(DEVICE)\n",
        "\n",
        "optimizer=optim.Adam(model.parameters()) #优化器，更新模型的参数，使得测试和训练的结果达到最优值"
      ],
      "metadata": {
        "id": "Fm-QFFDamo20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#7 定义训练方法\n",
        "def train_model(model,device,train_loader,optimizer,epoch):\n",
        "  #模型训练\n",
        "  model.train()\n",
        "  for batch_index,(data,target) in enumerate(train_loader):\n",
        "    #部署到DEVICE上去\n",
        "    data,target=data.to(device),target.to(device)\n",
        "    #梯度初始化为0\n",
        "    optimizer.zero_grad()\n",
        "    #训练后的结果\n",
        "    output=model(data)\n",
        "    #计算损失\n",
        "    loss=F.cross_entropy(output,target)\n",
        "    #反向传播\n",
        "    loss.backward()\n",
        "    #参数优化\n",
        "    optimizer.step()\n",
        "    if batch_index % 3000 == 0:\n",
        "      print(\"Train Epoch : {} \\t Loss : {:.6f}\".format(epoch,loss.item())) #每3000张图片打印一次loss，.6f：保留小数点后六位"
      ],
      "metadata": {
        "id": "t7s-pz14mrnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8 定义测试方法\n",
        "def test_model(model,device,test_loader):\n",
        "  #模型验证\n",
        "  model.eval()\n",
        "  #正确率\n",
        "  correct=0.0\n",
        "  #测试损失\n",
        "  test_loss=0.0\n",
        "  #开始测试\n",
        "  with torch.no_grad(): #不会计算梯度，也不会进行反向传播\n",
        "    for data,target in test_loader:\n",
        "      #部署到device上\n",
        "      data,target=data.to(device),target.to(device)\n",
        "      #测试数据\n",
        "      output=model(data)\n",
        "      #计算测试损失\n",
        "      test_loss+=F.cross_entropy(output,target).item()\n",
        "      #找到概率值最大的下标\n",
        "      pred=output.max(1,keepdim=True)[1] #1:横轴； 也可以写成：pred=output.argmax(dim=1); [1]:索引 [0]:值\n",
        "      #累计正确的值\n",
        "      correct/=pred.eq(target.view_as(pred)).sum().item()\n",
        "  #计算平均损失值\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "  print(\"Test-Average loss : {:4.4f},Accuracy:{:.3f}\\n\".format(test_loss,100*correct/len(test_loader.dataset)))\n"
      ],
      "metadata": {
        "id": "W8W77N67mt_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#9 调用 方法7/8\n",
        "for epoch in range(1,EPOCHS+1):\n",
        "  train_model(model,DEVICE,train_loader,optimizer,epoch)\n",
        "  test_model(model,DEVICE,test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iCbdFCOmyX6",
        "outputId": "f7e3bef4-1bd0-4f61-e84a-acb9a605088c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch : 1 \t Loss : 0.000003\n",
            "Test-Average loss : 0.0023,Accuracy:0.000\n",
            "\n",
            "Train Epoch : 2 \t Loss : 0.000041\n",
            "Test-Average loss : 0.0033,Accuracy:0.000\n",
            "\n",
            "Train Epoch : 3 \t Loss : 0.000021\n",
            "Test-Average loss : 0.0029,Accuracy:0.000\n",
            "\n",
            "Train Epoch : 4 \t Loss : 0.000282\n",
            "Test-Average loss : 0.0032,Accuracy:0.000\n",
            "\n",
            "Train Epoch : 5 \t Loss : 0.000007\n",
            "Test-Average loss : 0.0027,Accuracy:0.000\n",
            "\n",
            "Train Epoch : 6 \t Loss : 0.000007\n",
            "Test-Average loss : 0.0039,Accuracy:0.000\n",
            "\n",
            "Train Epoch : 7 \t Loss : 0.000000\n",
            "Test-Average loss : 0.0034,Accuracy:0.000\n",
            "\n",
            "Train Epoch : 8 \t Loss : 0.000001\n",
            "Test-Average loss : 0.0031,Accuracy:0.000\n",
            "\n",
            "Train Epoch : 9 \t Loss : 0.000000\n",
            "Test-Average loss : 0.0033,Accuracy:0.000\n",
            "\n",
            "Train Epoch : 10 \t Loss : 0.000000\n",
            "Test-Average loss : 0.0045,Accuracy:0.000\n",
            "\n",
            "Train Epoch : 11 \t Loss : 0.000000\n",
            "Test-Average loss : 0.0044,Accuracy:0.000\n",
            "\n",
            "Train Epoch : 12 \t Loss : 0.000000\n",
            "Test-Average loss : 0.0050,Accuracy:0.000\n",
            "\n",
            "Train Epoch : 13 \t Loss : 0.000000\n",
            "Test-Average loss : 0.0033,Accuracy:0.000\n",
            "\n",
            "Train Epoch : 14 \t Loss : 0.000000\n",
            "Test-Average loss : 0.0042,Accuracy:0.000\n",
            "\n",
            "Train Epoch : 15 \t Loss : 0.000000\n",
            "Test-Average loss : 0.0038,Accuracy:0.000\n",
            "\n",
            "Train Epoch : 16 \t Loss : 0.000008\n",
            "Test-Average loss : 0.0037,Accuracy:0.000\n",
            "\n",
            "Train Epoch : 17 \t Loss : 0.000000\n",
            "Test-Average loss : 0.0032,Accuracy:0.000\n",
            "\n",
            "Train Epoch : 18 \t Loss : 0.000003\n",
            "Test-Average loss : 0.0045,Accuracy:0.000\n",
            "\n",
            "Train Epoch : 19 \t Loss : 0.000000\n",
            "Test-Average loss : 0.0040,Accuracy:0.000\n",
            "\n",
            "Train Epoch : 20 \t Loss : 0.000000\n",
            "Test-Average loss : 0.0041,Accuracy:0.000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ud_VpBlSwpJK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}